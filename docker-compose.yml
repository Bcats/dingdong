version: '3.8'

services:
  # PostgreSQL数据库
  postgres:
    image: postgres:14-alpine
    container_name: notification-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: notification_db
      POSTGRES_USER: notification_user
      POSTGRES_PASSWORD: ${DB_PASSWORD:-changeme}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    ports:
      - "${DB_PORT:-5432}:5432"
    networks:
      - notification-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U notification_user -d notification_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis
  redis:
    image: redis:7-alpine
    container_name: notification-redis
    restart: unless-stopped
    command: redis-server --appendonly yes ${REDIS_PASSWORD:+--requirepass $REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - notification-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3.11-management-alpine
    container_name: notification-rabbitmq
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-admin}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-changeme}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"
      - "${RABBITMQ_MANAGEMENT_PORT:-15672}:15672"
    networks:
      - notification-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # FastAPI应用
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-api
    restart: unless-stopped
    command: python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers ${WORKERS:-4}
    volumes:
      - ./app:/app/app
      - ./logs:/app/logs
      - attachment_data:/data/attachments
    ports:
      - "${API_PORT:-8000}:8000"
    env_file:
      - .env
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - notification-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery Worker
  celery-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-worker
    restart: unless-stopped
    command: python -m celery -A app.tasks.celery_app worker --loglevel=${LOG_LEVEL:-info} --concurrency=${CELERY_WORKER_CONCURRENCY:-4} --max-tasks-per-child=1000
    volumes:
      - ./app:/app/app
      - ./logs:/app/logs
      - attachment_data:/data/attachments
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
      - rabbitmq
    networks:
      - notification-network
    healthcheck:
      test: ["CMD-SHELL", "python -m celery -A app.tasks.celery_app inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery Beat（定时任务）
  celery-beat:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-beat
    restart: unless-stopped
    command: python -m celery -A app.tasks.celery_app beat --loglevel=${LOG_LEVEL:-info}
    volumes:
      - ./app:/app/app
      - ./logs:/app/logs
      - celerybeat_data:/app  # Beat schedule文件持久化
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
      - rabbitmq
    networks:
      - notification-network
    healthcheck:
      test: ["CMD-SHELL", "test -f celerybeat-schedule || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Flower（Celery监控）
  flower:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-flower
    restart: unless-stopped
    command: python -m celery -A app.tasks.celery_app flower --port=5555 --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-changeme} --max_tasks=10000 --persistent=True --db=/data/flower.db
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    volumes:
      - flower_data:/data  # Flower数据持久化
    env_file:
      - .env
    depends_on:
      - rabbitmq
      - redis
    networks:
      - notification-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5555/healthcheck || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  attachment_data:
    driver: local
  celerybeat_data:
    driver: local
  flower_data:
    driver: local

networks:
  notification-network:
    driver: bridge

