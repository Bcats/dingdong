# 部署运维手册 - 消息通知平台

**版本**：v1.0  
**日期**：2025-10-24  
**适用环境**：开发/测试/生产  
**参考标准**：阿里云运维最佳实践

---

## 📋 目录

1. [环境要求](#一环境要求)
2. [快速开始](#二快速开始)
3. [详细部署步骤](#三详细部署步骤)
4. [配置说明](#四配置说明)
5. [运维操作](#五运维操作)
6. [监控告警](#六监控告警)
7. [故障排查](#七故障排查)
8. [常见问题](#八常见问题)

---

## 一、环境要求

### 1.1 硬件要求

#### 开发环境（最低配置）

| 组件 | 配置要求 |
|------|---------|
| CPU | 2核 |
| 内存 | 4GB |
| 硬盘 | 20GB |
| 网络 | 1Mbps |

#### 生产环境（推荐配置）

| 组件 | 配置要求 | 说明 |
|------|---------|------|
| CPU | 4核+ | 支持多并发处理 |
| 内存 | 8GB+ | 数据库和缓存需要较大内存 |
| 硬盘 | 100GB+ SSD | 数据库建议使用SSD |
| 网络 | 10Mbps+ | 保证SMTP连接稳定 |

### 1.2 软件要求

| 软件 | 版本要求 | 说明 |
|------|---------|------|
| Docker | 20.10+ | 容器运行环境 |
| Docker Compose | 2.0+ | 多容器编排 |
| Python | 3.10+ | 应用运行环境（容器内自动安装）|
| PostgreSQL | 14+ | 数据库（Docker镜像）|
| Redis | 7+ | 缓存和消息队列（Docker镜像）|
| RabbitMQ | 3.11+ | 消息队列（Docker镜像）|

### 1.3 操作系统要求

**支持的操作系统**：
- ✅ Linux (Ubuntu 20.04+, CentOS 7+, Debian 10+)
- ✅ macOS 11+
- ✅ Windows 10+ (WSL2)

**推荐**：Ubuntu 22.04 LTS

---

## 二、快速开始

### 2.1 一键部署（开发环境）

```bash
# 1. 克隆代码仓库
git clone https://github.com/your-org/notification-platform.git
cd notification-platform

# 2. 复制环境变量配置
cp .env.example .env

# 3. 修改环境变量（修改密码等敏感信息）
vim .env

# 4. 启动所有服务
docker-compose up -d

# 5. 查看服务状态
docker-compose ps

# 6. 查看日志
docker-compose logs -f

# 7. 初始化数据库
docker-compose exec api python -m alembic upgrade head

# 8. 创建初始API密钥
docker-compose exec api python scripts/create_api_key.py

# 9. 访问API文档
# 浏览器打开: http://localhost:8000/docs
```

### 2.2 验证部署

```bash
# 健康检查
curl http://localhost:8000/health

# 就绪检查
curl http://localhost:8000/health/ready

# 查看监控指标
curl http://localhost:8000/metrics

# 查看RabbitMQ管理界面
# 浏览器打开: http://localhost:15672
# 用户名: admin
# 密码: 在.env中配置的RABBITMQ_PASSWORD
```

**预期输出**：
```json
{
  "status": "healthy"
}
```

---

## 三、详细部署步骤

### 3.1 准备工作

#### 3.1.1 安装Docker和Docker Compose

**Ubuntu/Debian**：
```bash
# 更新包索引
sudo apt-get update

# 安装依赖
sudo apt-get install -y \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# 添加Docker官方GPG密钥
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# 设置Docker仓库
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# 安装Docker
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# 验证安装
docker --version
docker compose version

# 将当前用户添加到docker组（避免每次使用sudo）
sudo usermod -aG docker $USER
newgrp docker
```

**CentOS/RHEL**：
```bash
# 安装Docker
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# 启动Docker
sudo systemctl start docker
sudo systemctl enable docker

# 验证安装
docker --version
```

#### 3.1.2 配置系统参数

**优化Linux内核参数**：
```bash
# 编辑系统配置
sudo vim /etc/sysctl.conf

# 添加以下配置
vm.max_map_count=262144
net.core.somaxconn=65535
net.ipv4.tcp_max_syn_backlog=8192
fs.file-max=655360

# 应用配置
sudo sysctl -p
```

**配置文件描述符限制**：
```bash
# 编辑limits配置
sudo vim /etc/security/limits.conf

# 添加以下配置
* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535

# 重新登录使配置生效
```

### 3.2 部署应用

#### 3.2.1 获取代码

```bash
# 方式1：从Git仓库克隆
git clone https://github.com/your-org/notification-platform.git
cd notification-platform

# 方式2：从发布包解压
tar -xzf notification-platform-v1.0.0.tar.gz
cd notification-platform
```

#### 3.2.2 配置环境变量

```bash
# 复制配置文件
cp .env.example .env

# 编辑配置文件
vim .env
```

**重要配置项**（详见第四章）：
```env
# 数据库密码（必须修改）
DB_PASSWORD=your_secure_password_here

# RabbitMQ密码（必须修改）
RABBITMQ_PASSWORD=your_rabbitmq_password_here

# JWT密钥（必须修改，至少32位）
JWT_SECRET_KEY=your_jwt_secret_key_at_least_32_chars

# 加密密钥（必须修改，Base64编码）
ENCRYPTION_KEY=your_encryption_key_base64_encoded

# 环境标识
ENV=production
DEBUG=false
```

#### 3.2.3 生成加密密钥

```bash
# 生成Fernet加密密钥（Python）
python3 << EOF
from cryptography.fernet import Fernet
key = Fernet.generate_key()
print(f"ENCRYPTION_KEY={key.decode()}")
EOF

# 生成随机JWT密钥
openssl rand -base64 32

# 将生成的密钥填入.env文件
```

#### 3.2.4 启动服务

```bash
# 拉取镜像
docker-compose pull

# 启动所有服务
docker-compose up -d

# 查看启动日志
docker-compose logs -f

# 查看服务状态
docker-compose ps
```

**预期输出**：
```
NAME                    STATUS              PORTS
notification-api        Up 30 seconds       0.0.0.0:8000->8000/tcp
notification-worker     Up 30 seconds
notification-beat       Up 30 seconds
notification-db         Up 30 seconds       0.0.0.0:5432->5432/tcp
notification-redis      Up 30 seconds       0.0.0.0:6379->6379/tcp
notification-rabbitmq   Up 30 seconds       0.0.0.0:5672->5672/tcp, 0.0.0.0:15672->15672/tcp
```

#### 3.2.5 初始化数据库

```bash
# 进入API容器
docker-compose exec api bash

# 运行数据库迁移
alembic upgrade head

# 查看当前版本
alembic current

# 退出容器
exit
```

#### 3.2.6 创建初始数据

```bash
# 创建API密钥
docker-compose exec api python scripts/create_api_key.py \
  --name "默认密钥" \
  --description "系统初始化创建的API密钥"

# 输出示例：
# API Key: noti_abc123def456...
# API Secret: secret_xyz789... (请妥善保管！)
```

#### 3.2.7 导入邮箱账户

```bash
# 方式1：通过API导入（推荐）
curl -X POST http://localhost:8000/api/v1/admin/email-accounts \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "noreply@example.com",
    "smtp_host": "smtp.example.com",
    "smtp_port": 465,
    "smtp_username": "noreply@example.com",
    "smtp_password": "your_password",
    "display_name": "系统通知",
    "daily_limit": 500,
    "priority": 10
  }'

# 方式2：通过SQL导入
docker-compose exec -T db psql -U notification_user -d notification_db << EOF
INSERT INTO email_accounts (email, smtp_host, smtp_port, smtp_username, smtp_password, display_name, daily_limit, priority)
VALUES 
  ('account1@example.com', 'smtp.example.com', 465, 'account1@example.com', 'encrypted_password', 'Account 1', 500, 10),
  ('account2@example.com', 'smtp.example.com', 465, 'account2@example.com', 'encrypted_password', 'Account 2', 500, 5);
EOF
```

### 3.3 验证部署

#### 3.3.1 健康检查

```bash
# 检查所有服务
./scripts/health_check.sh

# 或手动检查
curl http://localhost:8000/health/ready | jq
```

#### 3.3.2 发送测试邮件

```bash
# 1. 获取Token
TOKEN=$(curl -s -X POST http://localhost:8000/api/v1/auth/token \
  -H "Content-Type: application/json" \
  -d '{
    "api_key": "YOUR_API_KEY",
    "api_secret": "YOUR_API_SECRET"
  }' | jq -r '.data.access_token')

# 2. 发送测试邮件
curl -X POST http://localhost:8000/api/v1/messages/email/send \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "to": "test@example.com",
    "subject": "测试邮件",
    "content": "<h1>这是一封测试邮件</h1><p>如果您收到此邮件，说明系统部署成功！</p>"
  }' | jq
```

---

## 四、配置说明

### 4.1 环境变量配置

#### 完整的.env配置文件

```env
# ==================== 环境配置 ====================
ENV=production                      # 环境: development/staging/production
DEBUG=false                         # 调试模式（生产环境必须为false）
LOG_LEVEL=INFO                      # 日志级别: DEBUG/INFO/WARNING/ERROR/CRITICAL

# ==================== 数据库配置 ====================
DATABASE_URL=postgresql://notification_user:your_password@postgres:5432/notification_db
DB_POOL_SIZE=5                      # 连接池大小
DB_MAX_OVERFLOW=15                  # 最大溢出连接数
DB_POOL_TIMEOUT=30                  # 连接超时（秒）
DB_POOL_RECYCLE=3600                # 连接回收时间（秒）
DB_ECHO=false                       # 是否打印SQL（生产环境false）

# ==================== Redis配置 ====================
REDIS_URL=redis://redis:6379/0
REDIS_MAX_CONNECTIONS=50            # 最大连接数
REDIS_SOCKET_TIMEOUT=5              # Socket超时（秒）
REDIS_SOCKET_CONNECT_TIMEOUT=5      # 连接超时（秒）

# ==================== RabbitMQ配置 ====================
RABBITMQ_URL=amqp://admin:your_rabbitmq_password@rabbitmq:5672/
RABBITMQ_PREFETCH_COUNT=10          # 消费者预取数量
RABBITMQ_HEARTBEAT=60               # 心跳间隔（秒）

# ==================== 应用配置 ====================
APP_NAME=notification-platform
APP_VERSION=1.0.0
SECRET_KEY=your-secret-key-at-least-32-chars-long
ALLOWED_HOSTS=*                     # 生产环境应指定具体域名

# ==================== JWT配置 ====================
JWT_SECRET_KEY=your-jwt-secret-key-at-least-32-chars
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=60               # Token有效期（分钟）
JWT_REFRESH_EXPIRE_DAYS=7           # 刷新Token有效期（天）

# ==================== 加密配置 ====================
ENCRYPTION_KEY=your-encryption-key-base64-encoded

# ==================== SMTP配置 ====================
EMAIL_TIMEOUT=30                    # SMTP超时（秒）
EMAIL_MAX_SIZE=20971520             # 邮件最大大小（20MB）
EMAIL_USE_TLS=true                  # 是否使用TLS

# ==================== 附件配置 ====================
ATTACHMENT_STORAGE_PATH=/data/attachments
ATTACHMENT_MAX_SIZE=10485760        # 单个附件最大10MB
ATTACHMENT_EXPIRE_DAYS=7            # 附件保留天数

# ==================== Celery配置 ====================
CELERY_BROKER_URL=amqp://admin:your_rabbitmq_password@rabbitmq:5672/
CELERY_RESULT_BACKEND=redis://redis:6379/1
CELERY_WORKER_CONCURRENCY=4         # Worker并发数
CELERY_TASK_TIME_LIMIT=300          # 任务超时（秒）
CELERY_TASK_SOFT_TIME_LIMIT=270     # 任务软超时（秒）

# ==================== 监控配置 ====================
PROMETHEUS_ENABLED=true             # 是否启用Prometheus
METRICS_PORT=9090                   # 监控指标端口

# ==================== 限流配置 ====================
RATE_LIMIT_ENABLED=true             # 是否启用限流
RATE_LIMIT_PER_MINUTE=100           # 每分钟请求限制

# ==================== 其他 ====================
TZ=Asia/Shanghai                    # 时区
PYTHONUNBUFFERED=1
WORKERS=4                           # Uvicorn worker数量
```

### 4.2 Docker Compose配置

#### 生产环境docker-compose.yml（优化版）

```yaml
version: '3.8'

services:
  # PostgreSQL数据库
  postgres:
    image: postgres:14
    container_name: notification-db
    restart: always
    environment:
      POSTGRES_DB: notification_db
      POSTGRES_USER: notification_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    ports:
      - "5432:5432"
    networks:
      - notification-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U notification_user"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis
  redis:
    image: redis:7-alpine
    container_name: notification-redis
    restart: always
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - notification-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3.11-management
    container_name: notification-rabbitmq
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 512MB
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    networks:
      - notification-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  # FastAPI应用
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile
      args:
        ENV: production
    container_name: notification-api
    restart: always
    command: >
      sh -c "alembic upgrade head &&
             uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4"
    volumes:
      - ./logs:/app/logs
      - attachment_data:/data/attachments
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - RABBITMQ_URL=${RABBITMQ_URL}
      - ENV=production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - notification-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Celery Worker
  celery-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-worker
    restart: always
    command: celery -A app.tasks worker --loglevel=info --concurrency=4 --max-tasks-per-child=1000
    volumes:
      - ./logs:/app/logs
      - attachment_data:/data/attachments
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - RABBITMQ_URL=${RABBITMQ_URL}
      - ENV=production
    depends_on:
      - postgres
      - redis
      - rabbitmq
    networks:
      - notification-network

  # Celery Beat
  celery-beat:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-beat
    restart: always
    command: celery -A app.tasks beat --loglevel=info
    volumes:
      - ./logs:/app/logs
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - RABBITMQ_URL=${RABBITMQ_URL}
    depends_on:
      - postgres
      - redis
      - rabbitmq
    networks:
      - notification-network

  # Flower (Celery监控)
  flower:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: notification-flower
    restart: always
    command: celery -A app.tasks flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
    depends_on:
      - rabbitmq
      - redis
    networks:
      - notification-network

  # Nginx (可选，生产环境推荐)
  nginx:
    image: nginx:alpine
    container_name: notification-nginx
    restart: always
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api
    networks:
      - notification-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  attachment_data:
    driver: local

networks:
  notification-network:
    driver: bridge
```

### 4.3 Nginx配置（生产环境）

**nginx/nginx.conf**：
```nginx
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 20M;

    # Gzip压缩
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml;

    # HTTP重定向到HTTPS
    server {
        listen 80;
        server_name api.example.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS配置
    server {
        listen 443 ssl http2;
        server_name api.example.com;

        # SSL证书配置
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # 安全头
        add_header Strict-Transport-Security "max-age=31536000" always;
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;

        # API代理
        location / {
            proxy_pass http://api:8000;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_redirect off;
            proxy_buffering off;
            proxy_request_buffering off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # 健康检查（不记录日志）
        location /health {
            proxy_pass http://api:8000;
            access_log off;
        }

        # WebSocket支持（如果需要）
        location /ws {
            proxy_pass http://api:8000;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }
    }
}
```

---

## 五、运维操作

### 5.1 日常操作

#### 5.1.1 查看服务状态

```bash
# 查看所有容器状态
docker-compose ps

# 查看资源使用情况
docker stats

# 查看特定服务日志
docker-compose logs -f api
docker-compose logs -f celery-worker

# 查看最近100行日志
docker-compose logs --tail=100 api
```

#### 5.1.2 重启服务

```bash
# 重启所有服务
docker-compose restart

# 重启特定服务
docker-compose restart api
docker-compose restart celery-worker

# 优雅重启（等待当前任务完成）
docker-compose stop api
docker-compose up -d api
```

#### 5.1.3 更新应用

```bash
# 1. 拉取最新代码
git pull origin main

# 2. 备份数据库
./scripts/backup_database.sh

# 3. 停止服务
docker-compose down

# 4. 重新构建镜像
docker-compose build --no-cache

# 5. 启动服务
docker-compose up -d

# 6. 运行数据库迁移
docker-compose exec api alembic upgrade head

# 7. 验证服务
curl http://localhost:8000/health/ready
```

#### 5.1.4 扩容Worker

```bash
# 临时扩容（重启后失效）
docker-compose up -d --scale celery-worker=4

# 永久扩容（修改docker-compose.yml）
# 在celery-worker服务下添加：
#   deploy:
#     replicas: 4

docker-compose up -d
```

### 5.2 数据备份

#### 5.2.1 数据库备份

**自动备份脚本（scripts/backup_database.sh）**：
```bash
#!/bin/bash

# 配置
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
FILENAME="notification_db_${DATE}.sql.gz"
KEEP_DAYS=7

# 创建备份目录
mkdir -p ${BACKUP_DIR}

# 执行备份
echo "开始备份数据库..."
docker-compose exec -T postgres pg_dump -U notification_user notification_db | gzip > ${BACKUP_DIR}/${FILENAME}

# 验证备份
if [ -f "${BACKUP_DIR}/${FILENAME}" ]; then
    echo "备份成功: ${FILENAME}"
    SIZE=$(ls -lh ${BACKUP_DIR}/${FILENAME} | awk '{print $5}')
    echo "备份大小: ${SIZE}"
else
    echo "备份失败！"
    exit 1
fi

# 清理旧备份
echo "清理${KEEP_DAYS}天前的备份..."
find ${BACKUP_DIR} -name "notification_db_*.sql.gz" -type f -mtime +${KEEP_DAYS} -delete

echo "备份完成！"
```

**设置定时备份（Crontab）**：
```bash
# 编辑crontab
crontab -e

# 添加定时任务（每天凌晨2点备份）
0 2 * * * /path/to/notification-platform/scripts/backup_database.sh >> /var/log/backup.log 2>&1
```

#### 5.2.2 数据库恢复

```bash
# 查看备份文件
ls -lh /backups/notification_db_*.sql.gz

# 恢复数据库
gunzip < /backups/notification_db_20251024_020000.sql.gz | \
  docker-compose exec -T postgres psql -U notification_user notification_db

# 验证恢复
docker-compose exec postgres psql -U notification_user -d notification_db -c "\dt"
```

### 5.3 日志管理

#### 5.3.1 日志轮转配置

**/etc/logrotate.d/notification-platform**：
```
/var/log/notification-platform/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root root
    sharedscripts
    postrotate
        docker-compose restart api > /dev/null 2>&1 || true
    endscript
}
```

#### 5.3.2 查看日志

```bash
# 实时查看所有日志
docker-compose logs -f

# 查看特定服务日志
docker-compose logs -f api

# 查看错误日志
docker-compose logs api | grep ERROR

# 导出日志到文件
docker-compose logs --no-color > logs_$(date +%Y%m%d).txt
```

---

## 六、监控告警

### 6.1 Prometheus配置

**prometheus.yml**：
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'notification-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
    
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
      
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

### 6.2 Grafana仪表板

**关键监控指标**：
- API请求量（QPS）
- API响应时间（P50/P95/P99）
- 消息发送成功率
- 队列长度
- 数据库连接数
- 系统资源使用率

### 6.3 告警规则

**alerts.yml**：
```yaml
groups:
  - name: notification_alerts
    rules:
      # API可用性告警
      - alert: APIDown
        expr: up{job="notification-api"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "API服务不可用"
          description: "{{ $labels.instance }} API服务已停止"

      # 消息发送失败率告警
      - alert: HighFailureRate
        expr: rate(messages_failed_total[5m]) / rate(messages_sent_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "消息发送失败率过高"
          description: "最近5分钟发送失败率超过5%"

      # 队列堆积告警
      - alert: QueueBacklog
        expr: rabbitmq_queue_messages > 1000
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "消息队列堆积"
          description: "队列消息数超过1000条"
```

---

## 七、故障排查

### 7.1 常见问题诊断

#### 7.1.1 服务无法启动

**问题表现**：
```bash
docker-compose up -d
# 容器不断重启
```

**排查步骤**：
```bash
# 1. 查看容器日志
docker-compose logs api

# 2. 检查端口占用
netstat -tlnp | grep 8000

# 3. 检查配置文件
cat .env | grep -v "^#" | grep -v "^$"

# 4. 检查磁盘空间
df -h

# 5. 检查内存
free -h
```

#### 7.1.2 数据库连接失败

**错误信息**：
```
sqlalchemy.exc.OperationalError: could not connect to server
```

**解决方案**：
```bash
# 1. 检查数据库容器状态
docker-compose ps postgres

# 2. 检查数据库日志
docker-compose logs postgres

# 3. 尝试手动连接
docker-compose exec postgres psql -U notification_user -d notification_db

# 4. 检查网络连接
docker-compose exec api ping postgres

# 5. 重启数据库
docker-compose restart postgres
```

#### 7.1.3 邮件发送失败

**排查步骤**：
```bash
# 1. 查看Worker日志
docker-compose logs celery-worker | grep ERROR

# 2. 检查邮箱账户状态
docker-compose exec api python << EOF
from app.services.email_service import EmailPoolManager
pool = EmailPoolManager()
account = pool.get_available_account()
print(f"可用邮箱: {account.email if account else 'None'}")
EOF

# 3. 测试SMTP连接
docker-compose exec api python << EOF
import smtplib
try:
    server = smtplib.SMTP_SSL('smtp.example.com', 465)
    server.login('user@example.com', 'password')
    print("SMTP连接成功")
    server.quit()
except Exception as e:
    print(f"SMTP连接失败: {e}")
EOF

# 4. 检查邮箱配置
docker-compose exec postgres psql -U notification_user -d notification_db -c \
  "SELECT email, is_active, daily_sent_count, daily_limit FROM email_accounts;"
```

### 7.2 性能问题诊断

#### 7.2.1 API响应慢

```bash
# 1. 查看慢查询
docker-compose exec postgres psql -U notification_user -d notification_db << EOF
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
EOF

# 2. 查看数据库连接
docker-compose exec postgres psql -U notification_user -d notification_db -c \
  "SELECT count(*) FROM pg_stat_activity;"

# 3. 查看Redis内存
docker-compose exec redis redis-cli INFO memory

# 4. 查看系统资源
docker stats --no-stream
```

#### 7.2.2 内存占用高

```bash
# 1. 查看容器内存使用
docker stats --no-stream | sort -k7 -h

# 2. 优化Worker并发数
# 修改docker-compose.yml中的--concurrency参数

# 3. 增加内存限制
# 在docker-compose.yml中添加:
#   deploy:
#     resources:
#       limits:
#         memory: 2G
```

---

## 八、常见问题

### 8.1 FAQ

#### Q1: 如何修改数据库密码？

**A**: 
```bash
# 1. 停止服务
docker-compose down

# 2. 修改.env文件中的DB_PASSWORD

# 3. 删除数据卷（注意：会清空数据）
docker volume rm notification-platform_postgres_data

# 4. 重新启动
docker-compose up -d

# 如果不想清空数据，需要进入数据库手动修改：
docker-compose exec postgres psql -U notification_user -d notification_db
ALTER USER notification_user WITH PASSWORD 'new_password';
```

#### Q2: 如何查看当前系统版本？

**A**:
```bash
curl http://localhost:8000/api/v1/version
```

#### Q3: 如何清理旧数据？

**A**:
```bash
# 清理30天前的消息记录
docker-compose exec postgres psql -U notification_user -d notification_db << EOF
DELETE FROM message_records WHERE created_at < NOW() - INTERVAL '30 days';
EOF

# 清理过期附件
docker-compose exec api python scripts/cleanup_attachments.py
```

#### Q4: 如何临时禁用某个邮箱账户？

**A**:
```bash
docker-compose exec postgres psql -U notification_user -d notification_db << EOF
UPDATE email_accounts SET is_active = false WHERE email = 'account@example.com';
EOF
```

#### Q5: 如何手动触发数据库备份？

**A**:
```bash
./scripts/backup_database.sh
```

### 8.2 性能优化建议

1. **数据库优化**：
   - 定期运行`VACUUM ANALYZE`
   - 添加适当的索引
   - 定期归档历史数据

2. **Redis优化**：
   - 设置maxmemory-policy
   - 定期清理过期键

3. **应用优化**：
   - 增加Worker数量
   - 使用连接池
   - 启用Redis缓存

4. **系统优化**：
   - 调整内核参数
   - 使用SSD硬盘
   - 增加系统内存

---

## 九、应急预案

### 9.1 服务宕机

**处理步骤**：
1. 确认故障范围
2. 查看监控和日志
3. 尝试重启服务
4. 如无法恢复，启动备用服务
5. 通知相关人员

### 9.2 数据库故障

**处理步骤**：
1. 立即停止写入
2. 从最近备份恢复
3. 检查数据完整性
4. 重启服务

### 9.3 联系方式

| 角色 | 姓名 | 电话 | 邮箱 |
|------|------|------|------|
| 运维负责人 | 张三 | 138xxxx | ops@example.com |
| 开发负责人 | 李四 | 139xxxx | dev@example.com |
| DBA | 王五 | 137xxxx | dba@example.com |

---

## 文档结束

本部署运维手册参考阿里云运维最佳实践编写，涵盖了消息通知平台的完整部署和运维流程。

**版本更新记录**：
- v1.0 (2025-10-24)：初始版本发布

**相关文档**：
- 开发规范手册
- 数据库设计文档
- API接口文档
- 故障处理手册

**技术支持**：
- 邮箱：support@example.com
- 文档：https://docs.example.com
- Issue：https://github.com/your-org/notification-platform/issues

